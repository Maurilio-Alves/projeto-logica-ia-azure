import os
import pyttsx3
from openai import AzureOpenAI
from dotenv import load_dotenv

# --- CONFIGURA√á√ÉO DE CAMINHO (O PULO DO GATO) ---
# Pega o local onde o jarvis.py est√° (ex: /src)
base_path = os.path.dirname(__file__)
# Aponta para o .env que est√° uma pasta acima
dotenv_path = os.path.join(base_path, '..', '.env')

# Carrega o .env do caminho espec√≠fico
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path)
else:
    load_dotenv() # Caso voc√™ rode na mesma pasta

# --- CONFIGURA√á√ïES DA AZURE ---
endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
chave = os.getenv("AZURE_OPENAI_KEY")
modelo = os.getenv("AZURE_OPENAI_DEPLOYMENT")

# --- FUN√á√ÉO DE VOZ (REINICIALIZADA) ---
def falar(texto):
    print(f"\nü§ñ JARVIS: {texto}")
    # Reinicia o motor para garantir que n√£o trave entre frases
    engine = pyttsx3.init()
    engine.setProperty('rate', 180)
    engine.setProperty('volume', 1.0)
    
    engine.say(texto)
    engine.runAndWait()
    engine.stop()

# --- VERIFICA√á√ÉO DE CREDENCIAIS ---
if not endpoint or not chave:
    print("‚ùå ERRO: O arquivo .env n√£o foi encontrado em: " + dotenv_path)
    exit()

# --- CLIENTE AZURE ---
client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=chave,
    api_version="2024-02-01"
)

# --- MEM√ìRIA E HIST√ìRICO ---
historico = [
    {"role": "system", "content": "Voc√™ √© o Jarvis. Responda de forma her√≥ica, curta e lembre-se do hist√≥rico da conversa."}
]

# Sauda√ß√£o inicial
falar("Sistemas de arquivos organizados. Estou pronto para a a√ß√£o, Maur√≠lio.")

while True:
    print("\n" + "="*45)
    pergunta = input("Sua pergunta (ou 'sair'): ")

    if not pergunta:
        continue

    if pergunta.lower() in ["sair", "parar", "tchau", "exit"]:
        falar("Entendido, senhor. At√© a pr√≥xima miss√£o!")
        break

    # Adiciona pergunta ao hist√≥rico
    historico.append({"role": "user", "content": pergunta})

    try:
        # Chamada para a IA
        response = client.chat.completions.create(
            model=modelo,
            messages=historico
        )

        resposta_texto = response.choices[0].message.content
        
        # Salva a resposta do assistente na mem√≥ria
        historico.append({"role": "assistant", "content": resposta_texto})
        
        # Fala a resposta
        falar(resposta_texto)

    except Exception as e:
        print(f"‚ùå Ocorreu um erro: {e}")
        falar("Sinto muito, Maur√≠lio. Tive um problema de comunica√ß√£o com a base de dados.")